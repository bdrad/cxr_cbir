{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1901fc9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b228c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ChestXray14\n",
    "from model import get_encoder\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from scipy.spatial.distance import cdist\n",
    "import random\n",
    "from einops import rearrange, repeat\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition, mark_inset\n",
    "from medcam import medcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ad715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/developer/.cache/torch/hub/facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 3330 images (Cardiomegaly)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3733633756637573: 100%|██████| 105/105 [00:12<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training Loss: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.834284782409668: 100%|███████| 52/52 [00:05<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Validation Loss: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4896389842033386: 100%|██████| 105/105 [00:11<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Training Loss: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4786471426486969: 100%|██████| 52/52 [00:05<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Validation Loss: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.16637155413627625: 100%|█████| 105/105 [00:11<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Training Loss: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.490084171295166: 100%|███████| 52/52 [00:06<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Validation Loss: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9920928478240967: 100%|██████| 105/105 [00:12<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Training Loss: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.40614938735961914:  92%|████▌| 48/52 [00:05<00:00,  8.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4041965/4176452098.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Adrian/Vision Transformer Image Retrieval/NIH/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(preprocess)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training on {} images ({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Adrian/Vision Transformer Image Retrieval/NIH/main.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, val_data_loader, class_name, preprocess)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_progress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cbir/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cbir/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cbir/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cbir/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cbir/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cbir/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cbir/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cbir/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cbir/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cbir/lib/python3.9/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from main import main\n",
    "main(\"HE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f6cb55",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50be741",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb06d1d",
   "metadata": {},
   "source": [
    "## Image Retrieval Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_tasks = [\n",
    "    'Cardiomegaly',\n",
    "    'Opacity',\n",
    "    'Emphysema',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060e0cc1",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(encoder_choice, class_name):\n",
    "    model_weights_path = 'weights/{}_{}_{}_weights'.format(encoder_choice, class_name, \"orig\")\n",
    "    model = get_encoder(encoder_choice=encoder_choice)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(model_weights_path))\n",
    "    model.eval()\n",
    "    images = []\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    test_dataset = ChestXray14(phase='test', class_name=class_name)\n",
    "    test_data_loader = DataLoader(test_dataset, shuffle=False)\n",
    "    progress_bar = tqdm.tqdm(test_data_loader)\n",
    "    progress_bar.set_description(class_name)\n",
    "    for data in progress_bar:\n",
    "        image, label = data\n",
    "        image, label = image.to(device), label.to(device)        \n",
    "        embedding = model(image)\n",
    "        image = image.cpu().detach().numpy()[0]\n",
    "        embedding = embedding.cpu().detach().numpy()[0]\n",
    "        label = label.cpu().detach().numpy()[0]\n",
    "        images.append(image)\n",
    "        embeddings.append(embedding)\n",
    "        labels.append(label)\n",
    "\n",
    "    images = np.array(images)\n",
    "    embeddings = np.array(embeddings)\n",
    "    labels = np.array(labels)\n",
    "    return images, embeddings, labels\n",
    "\n",
    "images = {}\n",
    "embeddings = {}\n",
    "labels = {}\n",
    "\n",
    "for task in retrieval_tasks:\n",
    "    encoder_choice = 'vit'\n",
    "    class_name = task\n",
    "    images[task], embeddings[task], labels[task] = data(encoder_choice, class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e16e79f",
   "metadata": {},
   "source": [
    "## Qualitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99fec85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 5, figsize=(20, 14))\n",
    "\n",
    "path = 'fonts/Roboto-Bold.ttf'\n",
    "fontprop = fm.FontProperties(fname=path, size=40)\n",
    "title1 = ax[0][0].set_title('Query', fontproperties=fontprop, pad=25)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "retrieval_indices = [481, 2722, 133]\n",
    "\n",
    "for task_index, task in enumerate(retrieval_tasks):\n",
    "    i = retrieval_indices[task_index]\n",
    "    nearest_neighbor_indices = cdist(embeddings[task], embeddings[task])[i].argsort()\n",
    "    nearest_neighbor_indices = nearest_neighbor_indices[nearest_neighbor_indices != i]\n",
    "    indices = [i]\n",
    "    indices.extend(nearest_neighbor_indices[:4])\n",
    "\n",
    "    for image_index, sub_ax in enumerate(ax[task_index]):\n",
    "        sub_ax.get_xaxis().set_ticks([])\n",
    "        sub_ax.get_yaxis().set_ticks([])\n",
    "        for spine in sub_ax.spines:\n",
    "            sub_ax.spines[spine].set_visible(False)\n",
    "        path = 'fonts/Roboto-Regular.ttf'\n",
    "        fontprop = fm.FontProperties(fname=path, size=25)\n",
    "        image = rearrange(images[task][indices[image_index]], 'c w h -> w h c')\n",
    "        sub_ax.imshow(image, cmap='Greys_r')\n",
    "        label = labels[task][indices[image_index]]\n",
    "        if label:\n",
    "            label = task\n",
    "        else:\n",
    "            label = 'No Finding'\n",
    "        sub_ax.text(0.5, -0.1, label, ha='center', va='top',\n",
    "               transform=sub_ax.transAxes, fontproperties=fontprop)\n",
    "\n",
    "plt.savefig('figures/query.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98ef22",
   "metadata": {},
   "source": [
    "## **Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings['Cardiomegaly']\n",
    "labels = labels['Cardiomegaly']\n",
    "images = images['Cardiomegaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6af350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at(k, i):\n",
    "    nearest_neighbor_indices = cdist(embeddings, embeddings)[i].argsort()\n",
    "    nearest_neighbor_indices = nearest_neighbor_indices[nearest_neighbor_indices != i]\n",
    "    indices = []\n",
    "    indices.extend(nearest_neighbor_indices[:k])\n",
    "    return sum(labels[indices] == labels[i]) / k\n",
    "\n",
    "p_at_5 = 0\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    p_at_5 += precision_at(k=5, i=i)\n",
    "    \n",
    "print('ViT: ', p_at_5 / len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86563cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "z = TSNE().fit_transform(embeddings)\n",
    "\n",
    "x, y = z[:, 0], z[:, 1]\n",
    "x = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "y = (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "\n",
    "positive_color = '#ED6B86'\n",
    "negative_color = '#5FBFF9'\n",
    "\n",
    "colors = [positive_color if labels[i] else negative_color for i in range(len(embeddings))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "ax.scatter(x, y, color=colors, s=100)\n",
    "\n",
    "for i in [180, 179, 177, 176, 347, 342, 340, 339]:  \n",
    "    img = rearrange(images[i], 'c w h -> w h c')\n",
    "    imgbox = OffsetImage(img, zoom=0.5, cmap='Greys_r')\n",
    "    ab = AnnotationBbox(imgbox, (x[i], y[i]),\n",
    "                    xycoords='data', boxcoords='offset points', bboxprops=dict(linewidth=0))\n",
    "    ax.add_artist(ab)    \n",
    "\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "for spine in ax.spines:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "\n",
    "plt.scatter(x, y, color=colors)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "path = 'fonts/Roboto-Regular.ttf'\n",
    "fontprop = fm.FontProperties(fname=path, size=25)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', label='Cardiomegaly', markerfacecolor=positive_color, markersize=20),\n",
    "    Line2D([0], [0], marker='o', color='w', label='No Findings',markerfacecolor=negative_color, markersize=20)\n",
    "]\n",
    "\n",
    "lgnd = ax.legend(handles=legend_elements, bbox_to_anchor=(0.25, 0.95), frameon=False, prop=fontprop)\n",
    "plt.savefig('figures/tsne.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d1cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame((list(zip(x,y))), columns=['x', 'y'])\n",
    "# x2, x1, y1, y2 = 0.45, 0.55, 0.5, 0.6\n",
    "# df = df[(df['x'] > x2) & (df['x'] < x1) & (df['y'] < y1) & (df['y'] > y2)]\n",
    "\n",
    "\n",
    "# inset_ax = fig.add_axes([0, 0, 1, 1], zorder=4, frameon=True)\n",
    "# inset_ax.set_axes_locator(InsetPosition(ax, [1.2, 0.6, 0.55, 0.55]))\n",
    "\n",
    "# inset_ax.get_xaxis().set_visible(False)\n",
    "# inset_ax.get_yaxis().set_visible(False)\n",
    "# for spine in ax.spines:\n",
    "#     inset_ax.spines[spine].set_color('#FF70A6')\n",
    "#     inset_ax.spines[spine].set_linewidth(5)\n",
    "\n",
    "# for i in range(len(embeddings)):    \n",
    "#     img = rearrange(images[i], 'c w h -> w h c')\n",
    "#     imgbox = OffsetImage(img, zoom=0.35, cmap='Greys_r')\n",
    "#     ab = AnnotationBbox(imgbox, (x[i], y[i]),\n",
    "#                     xycoords='data', boxcoords='offset points', bboxprops=dict(linewidth=0))\n",
    "#     inset_ax.add_artist(ab)\n",
    "\n",
    "# inset_ax.set_xlim(x1, x2)\n",
    "# inset_ax.set_ylim(y1, y2)\n",
    "\n",
    "# inset = mark_inset(ax, inset_ax, loc1=3, loc2=2, fc='none', ec='#FF70A6', lw=4)\n",
    "# inset[0].set_zorder(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc29e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.blocks[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabfbc37",
   "metadata": {},
   "source": [
    "## Saliency Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd5a68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, \\\n",
    "    ScoreCAM, \\\n",
    "    GradCAMPlusPlus, \\\n",
    "    AblationCAM, \\\n",
    "    XGradCAM, \\\n",
    "    EigenCAM, \\\n",
    "    EigenGradCAM, \\\n",
    "    LayerCAM, \\\n",
    "    FullGrad\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "encoder_choice = 'vit'\n",
    "class_name = 'Cardiomegaly'\n",
    "\n",
    "model_weights_path = 'weights/{}_{}_weights'.format(encoder_choice, class_name)\n",
    "model = get_encoder(encoder_choice=encoder_choice)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(model_weights_path))\n",
    "model.eval()\n",
    "\n",
    "target_layers = [model.blocks[-1].norm1]\n",
    "\n",
    "\n",
    "def reshape_transform(tensor, height=14, width=14):\n",
    "    result = tensor[:, 1:, :].reshape(tensor.size(0),\n",
    "                                      height, width, tensor.size(2))\n",
    "\n",
    "    # Bring the channels to the first dimension,\n",
    "    # like in CNNs.\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result\n",
    "\n",
    "cam = EigenCAM(model=model, target_layers=target_layers,\n",
    "                                   use_cuda=True,\n",
    "                                   reshape_transform=reshape_transform,\n",
    "                                 )\n",
    "# If None, returns the map for the highest scoring category.\n",
    "# Otherwise, targets the requested category.\n",
    "targets = None\n",
    "\n",
    "image = np.array([images[20]])\n",
    "image = torch.from_numpy(image)\n",
    "grayscale_cam = cam(input_tensor=image,\n",
    "                    targets=targets ,\n",
    "                    eigen_smooth=True,\n",
    "                    aug_smooth=False)\n",
    "\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "xray = rearrange(images[20], 'c w h -> w h c')\n",
    "\n",
    "cam_image = show_cam_on_image(xray, grayscale_cam, use_rgb=False)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 12))\n",
    "fig.subplots_adjust(hspace=0.05)\n",
    "\n",
    "ax[1].imshow(cam_image)\n",
    "\n",
    "for spine in ax[1].spines:\n",
    "    ax[1].spines[spine].set_visible(False)\n",
    "    \n",
    "ax[1].get_xaxis().set_ticks([])\n",
    "ax[1].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "ax[0].imshow(xray)\n",
    "\n",
    "for spine in ax[0].spines:\n",
    "    ax[0].spines[spine].set_visible(False)\n",
    "    \n",
    "xticks = ax[0].get_xaxis().set_ticks([])\n",
    "yticks = ax[0].get_yaxis().set_ticks([])\n",
    "\n",
    "path = 'fonts/Roboto-Regular.ttf'\n",
    "fontprop = fm.FontProperties(fname=path, size=25)\n",
    "\n",
    "label = ax[0].text(1.0, -0.05, 'Cardiomegaly Saliency Map', ha='center', va='top',\n",
    "               transform=ax[0].transAxes, fontproperties=fontprop)\n",
    "\n",
    "\n",
    "plt.savefig('figures/saliency.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff34e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbir",
   "language": "python",
   "name": "cbir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
