{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-27T08:23:15.977174Z",
     "iopub.status.busy": "2021-12-27T08:23:15.976901Z",
     "iopub.status.idle": "2021-12-27T08:23:15.984773Z",
     "shell.execute_reply": "2021-12-27T08:23:15.983671Z",
     "shell.execute_reply.started": "2021-12-27T08:23:15.977137Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import  nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "from torchvision import transforms, utils\n",
    "import skimage.io as skio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:23:15.987919Z",
     "iopub.status.busy": "2021-12-27T08:23:15.986565Z",
     "iopub.status.idle": "2021-12-27T08:23:16.310308Z",
     "shell.execute_reply": "2021-12-27T08:23:16.309531Z",
     "shell.execute_reply.started": "2021-12-27T08:23:15.987829Z"
    }
   },
   "outputs": [],
   "source": [
    "_metadata = pd.read_csv(\"/kaggle/input/data/Data_Entry_2017.csv\")\n",
    "_metadata.loc[_metadata[\"Finding Labels\"].str.contains(\"No Finding\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:23:16.312637Z",
     "iopub.status.busy": "2021-12-27T08:23:16.311878Z",
     "iopub.status.idle": "2021-12-27T08:23:23.813180Z",
     "shell.execute_reply": "2021-12-27T08:23:23.812122Z",
     "shell.execute_reply.started": "2021-12-27T08:23:16.312596Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:23:23.817135Z",
     "iopub.status.busy": "2021-12-27T08:23:23.816734Z",
     "iopub.status.idle": "2021-12-27T08:23:23.829232Z",
     "shell.execute_reply": "2021-12-27T08:23:23.827410Z",
     "shell.execute_reply.started": "2021-12-27T08:23:23.817086Z"
    }
   },
   "outputs": [],
   "source": [
    "import einops\n",
    "def show_image(image):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def rearrange_tensor(img):\n",
    "    return einops.rearrange(img, \"c w h -> w h c\")\n",
    "\n",
    "def unnormalize_tensor(img):   \n",
    "    img = img.detach().numpy()\n",
    "    img = einops.rearrange(img, \"c w h -> w h c\")\n",
    "\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std =  np.array([0.229, 0.224, 0.225])\n",
    "    img = (img * std) + mean\n",
    "    return img\n",
    "\n",
    "def unnormalize_img(img):   \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std =  np.array([0.229, 0.224, 0.225])\n",
    "    img = (img * std) + mean\n",
    "    return img\n",
    "\n",
    "\n",
    "def normalize_image(img):\n",
    "    # normalize all images, this is necessary prepreocessing of inputs for vgg network\n",
    "    normalize = transforms.Compose([\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize(256), \n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                                          (0.229, 0.224, 0.225))\n",
    "                    ])\n",
    "    img = normalize(img)\n",
    "#     img = img[:3,:,:].unsqueeze(0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset, dataloader, and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:23:23.831708Z",
     "iopub.status.busy": "2021-12-27T08:23:23.831109Z",
     "iopub.status.idle": "2021-12-27T08:23:23.847908Z",
     "shell.execute_reply": "2021-12-27T08:23:23.847062Z",
     "shell.execute_reply.started": "2021-12-27T08:23:23.831670Z"
    }
   },
   "outputs": [],
   "source": [
    "class MulticlassChestDataset(Dataset):\n",
    "    def __init__(self, val = False):\n",
    "        _metadata = pd.read_csv(\"input/data/Data_Entry_2017.csv\")\n",
    "#         _metadata = _metadata.sample(frac = 1)\n",
    "        num_train = int(.6 * len(_metadata))\n",
    "        num_val = int(.4 * len(_metadata))\n",
    "        self.metadata = _metadata\n",
    "        self.num_train = num_train\n",
    "        self.num_val = num_val\n",
    "        self.data = {}\n",
    "        self.val = val\n",
    "        self.classes = {\"Atelectasis\" : 0, \"Cardiomegaly\" : 1, \"Effusion\" : 2, \"Infiltration\" : 3, \"Mass\" : 4, \"Nodule\" : 5, \"Pneumonia\" : 6, \"Pneumothorax\" : 7, \n",
    "                        \"Consolidation\" : 8, \"Edema\" : 9, \"Emphysema\" : 10, \n",
    "                        \"Fibrosis\" : 11, \"Pleural_Thickening\" : 12, \"Hernia\" : 13, \"No Finding\" : 14}\n",
    "    def __len__(self): \n",
    "        if not self.val:\n",
    "            return self.num_train\n",
    "        return self.num_val\n",
    "    def __getitem__(self, idx):\n",
    "        if self.val:\n",
    "            idx += self.num_train\n",
    "        if idx in self.data:\n",
    "            return self.data[idx]\n",
    "        file_name = self.metadata.iloc[idx][\"Image Index\"]\n",
    "        row = self.metadata.iloc[idx].name\n",
    "        folder_num = 1\n",
    "        if row >= 4999:\n",
    "            folder_num = (row - 4999) // 10000 + 2\n",
    "        image_file_path = \"input/data/images_\" + str(folder_num).zfill(3) + \"/images/\" + file_name\n",
    "        img = skio.imread(image_file_path)\n",
    "        if len(img.shape) >= 3:\n",
    "            img = img[:, :, 0]\n",
    "        label = self.metadata.iloc[idx][\"Finding Labels\"]\n",
    "        splitted = label.split(\"|\")\n",
    "        vectorized_label = np.zeros((15, 1), dtype = \"double\")\n",
    "        for diagnosis in splitted:\n",
    "            vectorized_label[self.classes[diagnosis]] = 1.0\n",
    "#         tensor_label = torch.from_numpy(vectorized_label)\n",
    "#         tensor_label = tensor_label.unsqueeze(2)\n",
    "        # turn 1-channel image to 3-channel image\n",
    "        img = np.stack((img,)*3, axis=-1)\n",
    "        # crop & normalize\n",
    "        img = normalize_image(img)\n",
    "        return img, vectorized_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:23:24.173035Z",
     "iopub.status.busy": "2021-12-27T08:23:24.172837Z",
     "iopub.status.idle": "2021-12-27T08:23:24.732747Z",
     "shell.execute_reply": "2021-12-27T08:23:24.732022Z",
     "shell.execute_reply.started": "2021-12-27T08:23:24.173010Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_dataset = MulticlassChestDataset()\n",
    "train_data_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "validation_dataset = MulticlassChestDataset(val = True)\n",
    "validation_data_loader = DataLoader(validation_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:23:24.734494Z",
     "iopub.status.busy": "2021-12-27T08:23:24.734206Z",
     "iopub.status.idle": "2021-12-27T08:23:24.740782Z",
     "shell.execute_reply": "2021-12-27T08:23:24.739893Z",
     "shell.execute_reply.started": "2021-12-27T08:23:24.734457Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:23:06.266370Z",
     "iopub.status.busy": "2021-12-27T08:23:06.265685Z",
     "iopub.status.idle": "2021-12-27T08:23:15.889595Z",
     "shell.execute_reply": "2021-12-27T08:23:15.888466Z",
     "shell.execute_reply.started": "2021-12-27T08:23:06.266331Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip -q install vit_pytorch linformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:29:58.739755Z",
     "iopub.status.busy": "2021-12-27T08:29:58.739001Z",
     "iopub.status.idle": "2021-12-27T08:29:58.788268Z",
     "shell.execute_reply": "2021-12-27T08:29:58.787626Z",
     "shell.execute_reply.started": "2021-12-27T08:29:58.739693Z"
    }
   },
   "outputs": [],
   "source": [
    "from vit_pytorch.efficient import ViT\n",
    "from linformer import Linformer\n",
    "efficient_transformer = Linformer(\n",
    "    dim=128,\n",
    "    seq_len=50,  # 7x7 patches + 1 cls-token\n",
    "    depth=12,\n",
    "    heads=8,\n",
    "    k=64\n",
    ")\n",
    "\n",
    "model = ViT(\n",
    "    dim=128,\n",
    "    image_size=224,\n",
    "    patch_size=32,\n",
    "    num_classes=15,\n",
    "    transformer=efficient_transformer,\n",
    "    channels=3,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:29:59.558408Z",
     "iopub.status.busy": "2021-12-27T08:29:59.557953Z",
     "iopub.status.idle": "2021-12-27T08:29:59.562385Z",
     "shell.execute_reply": "2021-12-27T08:29:59.561446Z",
     "shell.execute_reply.started": "2021-12-27T08:29:59.558371Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "lr = 3e-4\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:30:00.786253Z",
     "iopub.status.busy": "2021-12-27T08:30:00.785666Z",
     "iopub.status.idle": "2021-12-27T08:30:00.792527Z",
     "shell.execute_reply": "2021-12-27T08:30:00.791338Z",
     "shell.execute_reply.started": "2021-12-27T08:30:00.786211Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "# TODO: try triplet or siamese losses. Used for typical CBIR tasks\n",
    "criterion = nn.BCEWithLogitsLoss() # nn.TripletMarginLoss(margin=0.1) \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:30:01.096967Z",
     "iopub.status.busy": "2021-12-27T08:30:01.096590Z",
     "iopub.status.idle": "2021-12-27T08:46:07.825148Z",
     "shell.execute_reply": "2021-12-27T08:46:07.824417Z",
     "shell.execute_reply.started": "2021-12-27T08:30:01.096935Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "checkpoint_file = \"model_weights\"\n",
    "sigmoid = nn.Sigmoid()\n",
    "epoch = 0\n",
    "\n",
    "# if os.path.exists(checkpoint_file):\n",
    "#     print('gathering info from checkpoint file')\n",
    "#     checkpoint = torch.load(checkpoint_file)\n",
    "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     criterion.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#     epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "for epoch in range(epoch, epochs + epoch):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    # Wrap in a progress bar to display progress during training.\n",
    "    progress_bar = tqdm.tqdm(train_data_loader)\n",
    "    \n",
    "    for i, inputs in enumerate(progress_bar):\n",
    "        data, label = inputs\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        \n",
    "        \n",
    "        loss = criterion(sigmoid(output), label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.set_description(f\"Loss: {loss}\")\n",
    "        \n",
    "        output = output.detach().cpu().numpy()\n",
    "        \n",
    "        output = np.where(output < 0.5, 0.0, 1.0)\n",
    "        label = label.detach().cpu().numpy()\n",
    "\n",
    "#         correct_classifications = np.where((output == label)& (output == 1.0), 1.0, 0.0)\n",
    "#         i = 3\n",
    "#         acc = np.sum(correct_classifications[i] == label[i]) #!= output[5])\n",
    "\n",
    "        acc_arr = []\n",
    "        for i in range(len(output)):\n",
    "            num_elements = len(output[0])\n",
    "            acc_arr.append((num_elements - np.sum(output[i] != label[i])) / num_elements)\n",
    "            #acc2 += (num_elements - np.sum(output[i] != label[i])) / num_elements\n",
    "            \n",
    "        #acc = acc / len(output)\n",
    "\n",
    "        acc = np.mean(acc_arr) #(output.argmax(dim=1) == label).float().mean()\n",
    "        epoch_accuracy += acc / len(train_data_loader)\n",
    "        epoch_loss += loss / len(train_data_loader)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        for data, label in tqdm.tqdm(validation_data_loader):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(sigmoid(val_output), label)\n",
    "            \n",
    "            acc_arr = []\n",
    "            for i in range(len(val_output)):\n",
    "                num_elements = len(val_output[0])\n",
    "                acc_arr.append((num_elements - np.sum(val_output[i] != label[i])) / num_elements)\n",
    "                #acc2 += (num_elements - np.sum(output[i] != label[i])) / num_elements\n",
    "\n",
    "            #acc = acc / len(output)\n",
    "\n",
    "            acc = np.mean(acc_arr)\n",
    "            epoch_val_accuracy += acc / len(validation_data_loader)\n",
    "            epoch_val_loss += val_loss / len(validation_data_loader)\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': criterion.state_dict(),\n",
    "                'acc': epoch_accuracy,\n",
    "                'loss': epoch_loss,\n",
    "                'validation_acc' : epoch_val_accuracy,\n",
    "                'validation_loss': epoch_val_loss,\n",
    "                }, checkpoint_file)\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-27T07:50:47.563292Z",
     "iopub.status.idle": "2021-12-27T07:50:47.563719Z",
     "shell.execute_reply": "2021-12-27T07:50:47.563517Z",
     "shell.execute_reply.started": "2021-12-27T07:50:47.563494Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/kaggle/input/model-weights/model_weights\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "criterion.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-27T07:50:47.565149Z",
     "iopub.status.idle": "2021-12-27T07:50:47.565569Z",
     "shell.execute_reply": "2021-12-27T07:50:47.565368Z",
     "shell.execute_reply.started": "2021-12-27T07:50:47.565345Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:47:31.531087Z",
     "iopub.status.busy": "2021-12-27T08:47:31.530429Z",
     "iopub.status.idle": "2021-12-27T08:47:31.536693Z",
     "shell.execute_reply": "2021-12-27T08:47:31.536041Z",
     "shell.execute_reply.started": "2021-12-27T08:47:31.531047Z"
    }
   },
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "def get_latent(vit_model, img):\n",
    "    x = vit_model.to_patch_embedding(img)\n",
    "    b, n, _ = x.shape\n",
    "\n",
    "    cls_tokens = repeat(vit_model.cls_token, '() n d -> b n d', b = b)\n",
    "    x = torch.cat((cls_tokens, x), dim=1)\n",
    "    x += vit_model.pos_embedding[:, :(n + 1)]\n",
    "    x = vit_model.transformer(x)\n",
    "\n",
    "    x = x.mean(dim = 1) if vit_model.pool == 'mean' else x[:, 0]\n",
    "\n",
    "    return vit_model.to_latent(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:47:59.262839Z",
     "iopub.status.busy": "2021-12-27T08:47:59.262070Z",
     "iopub.status.idle": "2021-12-27T08:47:59.267303Z",
     "shell.execute_reply": "2021-12-27T08:47:59.266584Z",
     "shell.execute_reply.started": "2021-12-27T08:47:59.262718Z"
    }
   },
   "outputs": [],
   "source": [
    "unshuffled_train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:49:06.189958Z",
     "iopub.status.busy": "2021-12-27T08:49:06.189085Z",
     "iopub.status.idle": "2021-12-27T08:51:13.002172Z",
     "shell.execute_reply": "2021-12-27T08:51:13.000794Z",
     "shell.execute_reply.started": "2021-12-27T08:49:06.189903Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = np.zeros((len(train_dataset), 128))\n",
    "labels = []\n",
    "model.eval()\n",
    "imgs = []\n",
    "for i, sample in enumerate(tqdm.tqdm(unshuffled_train_dataloader)):\n",
    "    img, label = sample\n",
    "    labels.append(int(label))\n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "    embedding = get_latent(model, img)\n",
    "    embeddings[i] = (embedding.cpu().detach().numpy())\n",
    "    original_image = unnormalize_img(einops.rearrange(img.cpu().detach().numpy(), \"b c w h -> w h (b c)\"))\n",
    "    imgs.append(original_image)\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T07:09:38.77019Z",
     "iopub.status.busy": "2021-12-27T07:09:38.769931Z",
     "iopub.status.idle": "2021-12-27T07:09:43.791006Z",
     "shell.execute_reply": "2021-12-27T07:09:43.789978Z",
     "shell.execute_reply.started": "2021-12-27T07:09:38.77016Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"imgs.npy\", imgs)\n",
    "\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'imgs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:51:13.004494Z",
     "iopub.status.busy": "2021-12-27T08:51:13.003793Z",
     "iopub.status.idle": "2021-12-27T08:51:44.402539Z",
     "shell.execute_reply": "2021-12-27T08:51:44.401767Z",
     "shell.execute_reply.started": "2021-12-27T08:51:13.004453Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# The default of 1,000 iterations gives fine results, but I'm training for longer just to eke\n",
    "# out some marginal improvements. NB: This takes almost an hour!\n",
    "tsne = TSNE()\n",
    "\n",
    "low_dim_embeddings = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:51:44.404464Z",
     "iopub.status.busy": "2021-12-27T08:51:44.404183Z",
     "iopub.status.idle": "2021-12-27T08:51:44.795217Z",
     "shell.execute_reply": "2021-12-27T08:51:44.794543Z",
     "shell.execute_reply.started": "2021-12-27T08:51:44.404424Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = {0: 'red', 1: 'blue'}\n",
    "c = labels\n",
    "plt.scatter(low_dim_embeddings[:, 0], low_dim_embeddings[:, 1], c=c, cmap = \"Accent\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:51:44.797689Z",
     "iopub.status.busy": "2021-12-27T08:51:44.797210Z",
     "iopub.status.idle": "2021-12-27T08:51:44.802595Z",
     "shell.execute_reply": "2021-12-27T08:51:44.801960Z",
     "shell.execute_reply.started": "2021-12-27T08:51:44.797650Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def closest_node(node, nodes):\n",
    "    return np.argsort(distance.cdist(node, nodes))[:, :5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:51:44.804615Z",
     "iopub.status.busy": "2021-12-27T08:51:44.804143Z",
     "iopub.status.idle": "2021-12-27T08:51:44.814116Z",
     "shell.execute_reply": "2021-12-27T08:51:44.813258Z",
     "shell.execute_reply.started": "2021-12-27T08:51:44.804579Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "def image_grid(img_arr):\n",
    "    fig = plt.figure(figsize=(20., 20.))\n",
    "    grid = ImageGrid(fig, 111, \n",
    "                     nrows_ncols=(1, 5),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes\n",
    "                     )\n",
    "\n",
    "    for ax, im in zip(grid, img_arr):\n",
    "        ax.imshow(im)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:52:17.751126Z",
     "iopub.status.busy": "2021-12-27T08:52:17.750842Z",
     "iopub.status.idle": "2021-12-27T08:52:20.864139Z",
     "shell.execute_reply": "2021-12-27T08:52:20.862687Z",
     "shell.execute_reply.started": "2021-12-27T08:52:17.751094Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = closest_node(np.array([[40,40]]), low_dim_embeddings)\n",
    "top_images = np.array(imgs)[indices]\n",
    "print(\"CARDIOMEGALY IMAGES:\")\n",
    "print(np.array(labels)[indices])\n",
    "image_grid(top_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-27T08:53:28.187195Z",
     "iopub.status.busy": "2021-12-27T08:53:28.186423Z",
     "iopub.status.idle": "2021-12-27T08:53:30.871132Z",
     "shell.execute_reply": "2021-12-27T08:53:30.869527Z",
     "shell.execute_reply.started": "2021-12-27T08:53:28.187140Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = closest_node(np.array([[20,-100]]), low_dim_embeddings)\n",
    "top_images = np.array(imgs)[indices]\n",
    "print(\"NO FINDING IMAGES:\")\n",
    "print(np.array(labels)[indices])\n",
    "image_grid(top_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to create a more user-friendly UI for looking at images at given points. Not working yet. \n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(111)\n",
    "cmap = {0: 'red', 1: 'blue'}\n",
    "c = labels\n",
    "x = low_dim_embeddings[:, 0]\n",
    "y = low_dim_embeddings[:, 1]\n",
    "ax.scatter(low_dim_embeddings[:, 0], low_dim_embeddings[:, 1], c=c, cmap = \"Accent\")\n",
    "# ax.colorbar()\n",
    "\n",
    "def onclick(event):\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    print(\"I clicked at x={0:5.2f}, y={1:5.2f}\".format(ix,iy))\n",
    "\n",
    "    # Calculate, based on the axis extent, a reasonable distance \n",
    "    # from the actual point in which the click has to occur (in this case 5%)\n",
    "    ax = plt.gca()\n",
    "    dx = 0.05 * (ax.get_xlim()[1] - ax.get_xlim()[0])\n",
    "    dy = 0.05 * (ax.get_ylim()[1] - ax.get_ylim()[0])\n",
    "\n",
    "    # Check for every point if the click was close enough:\n",
    "    for i in range(len(x)):\n",
    "        if(x[i] > ix-dx and x[i] < ix+dx and y[i] > iy-dy and y[i] < iy+dy):\n",
    "            plt.imshow(imgs[i])\n",
    "            print(\"You clicked close enough!\")\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
